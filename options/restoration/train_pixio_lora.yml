name: PixIO_Restoration_lora_amp # 实验/项目名称，用于日志记录
model_type: PixIORestoration # 模型类型，标识这是一个图像恢复模型
num_gpu: 1 # 使用的 GPU 数量（当前代码暂未完全支持多 GPU 分布式，仅作占位）
manual_seed: 42 # 随机种子，保证结果可复现

datasets:
  train:
    name: gopro-train
    type: PairedImageDataset
    dataroot_gt: /home/share/deblur/GoPro_datasets/GoPro/train/sharp_crops.lmdb
    dataroot_lq: /home/share/deblur/GoPro_datasets/GoPro/train/blur_crops.lmdb
    io_backend:
      type: lmdb # 数据读取后端，支持 'disk' (直接读取图片) 或 'lmdb' (数据库读取)
    
    gt_size: 256 # 训练时裁剪的 Ground Truth 图像尺寸 (Patch Size)
    use_flip: true # 是否开启随机水平翻转增强
    use_rot: true # 是否开启随机旋转增强

    # data loader 配置
    use_shuffle: true # 是否打乱数据
    num_worker_per_gpu: 4 # 每个 GPU 分配的数据加载线程数
    batch_size_per_gpu: 64 # 每个 GPU 的 Batch Size
    dataset_enlarge_ratio: 1 # 数据集放大倍率（用于增加每个 epoch 的迭代次数，当前代码可能未实装）
    mean: [0.485, 0.456, 0.406]
    std: [0.229, 0.224, 0.225]
  val:
    name: gopro-test
    type: PairedImageDataset
    dataroot_gt: /home/share/deblur/GoPro_datasets/GoPro/test/target.lmdb
    dataroot_lq: /home/share/deblur/GoPro_datasets/GoPro/test/input.lmdb
    io_backend:
      type: lmdb
    mean: [0.485, 0.456, 0.406]
    std: [0.229, 0.224, 0.225]

network_g:
  type: pixio_vitb16_enc768x12h12_dec512x32h16 # 生成器网络架构类型: ViT-B (Base)
  pretrained_path: /home/leris/.cache/huggingface/hub/models--facebook--pixio-vitb16/snapshots/dd8987ed2d276f81eceb58c797fb851ab83dd557/pixio_vitb16.pth
  mask_ratio: 0.0 # 掩码率 (0.0 表示保留全部 Patch，适合全图恢复任务；预训练时通常为 0.75)
  
  # 训练策略配置
  training_strategy: lora # 可选: 'full' (全量微调), 'freeze_encoder' (冻结 Encoder 仅微调 Decoder), 'lora' (使用 LoRA)
  
  # LoRA 配置 (仅当 training_strategy: lora 时生效)
  lora:
    r: 16 # LoRA 秩 (Rank)，图像恢复任务建议设大一点 (16-64)
    alpha: 32 # LoRA alpha, 通常设为 r 的 1-2 倍
    dropout: 0.05
    target_modules: ["qkv", "proj", "fc1", "fc2"] # 需要注入 LoRA 的层，支持 Attention (qkv, proj) 和 MLP (fc1, fc2)

train:
  optim_g:
    type: AdamW # 优化器类型
    lr: !!float 1e-4 # 初始学习率
    weight_decay: 0.05 # 权重衰减 (L2 正则化) 参数
    betas: [0.9, 0.95] # AdamW 的 beta 参数

  scheduler:
    type: CosineAnnealingLR # 学习率调度器类型: CosineAnnealingLR (余弦退火)
    T_max: 100000 # 周期长度，通常设为 total_iter
    eta_min: !!float 1e-7 # 最小学习率

  total_iter: 100000 # 总训练迭代次数 (Iterations)
  warmup_iter: 5000 # 预热迭代次数，在此期间学习率线性增加
  use_amp: true # 是否开启混合精度训练 (AMP)

  # 损失函数配置
  pixel_opt:
    type: L1Loss # 像素级损失函数类型
    loss_weight: 1.0 # 损失权重

validation:
  val_freq: 5000 # 验证频率
  visual_freq: 1000 # 可视化频率
  save_img: true # 是否保存验证集的可视化结果

logger:
  print_freq: 100 # 打印训练日志的频率 (Iterations)
  save_checkpoint_freq: 20000 # 保存模型权重的频率 (Iterations)
  swanlab:
    project: Pixio # SwanLab 项目名称
    experiment_name: Pixio_lora_256_amp_1U # SwanLab 实验名称

path:
  experiments_root: ./experiments/restoration_lora # 实验结果（日志、模型）保存的根目录
